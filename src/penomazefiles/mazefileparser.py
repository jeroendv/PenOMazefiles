'''
File: 2012_2013_parser.py
Author: Jeroen De Vlieger
Description: 

P&O 2012-2013 maze file parser

This module can build a maze object correcponding to the maze specified in a mazefile.

The maze file describes a rectangular maze. It first list the width and
height of the maze followed by a list of tiles. Each tile has type and
orientation. A tile can also boast a barcode, player start position or
the presence of an object.

see Toledo for specifications of mazefiles
'''

def MazeFileBuilder(stream):
    """
    Parse a stream of lines to build a Maze object

    Return a Maze 
    """
    token_stream = MazeFileTokenizer(stream)

    mazefile_parser = MazeFileParser()
    token_stream.addTokenConsumer(mazefile_parser)


    mazetoken_parser = MazeTokenParser()
    mazefile_parser.add_token_parser(mazetoken_parser)

    token_stream.start()
    return mazetoken_parser.getMaze()



class MazeFileTokenizer(object):
    """
    Filter out comments from a sequence of text lines and split it in tokens.
    These tokens are then given to a TokenConsumer for further processing.

    Each strings represents a single line from a mazefile. Comments start with
    a '#' character and run till the end of the line.

    mazefile tokens are single words seperated by a newline or white space.
    """

    token_consumer = None
    stream = None

    def __init__(self,stream):
        """
        Create a new MazeFileTokenizer object to tokenize a stream of text 
        lines.
        """
        self.stream = stream

    def addTokenConsumer(self,token_consumer):
        """subscribe a token consumer that will process all the tokens 
        generated from the stream of text lines when start() is invoked.
        """
        self.token_consumer = token_consumer

    def start(self):
        """
        Process the stream of text lines producing a sequence of tokens that 
        are to be processed by the consumer.
        """
        if self.token_consumer is None:
            return

        for line in self.stream:
            # remove comments
            comment_start_index = line.find('#')
            if(comment_start_index != -1):
                line = line[0:comment_start_index]

            # remove leading and trailing white space
            line = line.strip()

            # skip empty lines
            if len(line) == 0:
                continue

            # split line in tokens
            tokens = line.split()
            for token in tokens:
                self.token_consumer(token)

class TokenConsumer(object):
    """
    Abstract Consumer object for maze file Tokens
    """
        
    def consume(self, token):
        """Consume mazefile tokens"""
        raise NotImplementedError()


class MazeFileParser(TokenConsumer):
    """
    This object is a consumer for the tokens generated by the MazeFileTokenizer 
    from a mazefile. A mazefile describes a rectangular maze with implicitly 
    defined tile coordinates, this Token consumer enriches the token with 
    explicit coordinates for the construction of a freeform Maze object.

    The parsing of these token is left to a token parser.

    """

    width = None
    height = None

    currentX = 0
    currentY = 0

    maze_token_parser = None

    def add_token_parser(self, token_parser):
        self.maze_token_parser = token_parser
    

    def consume(self, token):
        """Consume mazefile tokens"""
        pass


class MazeTokenParser(object):
    """Class to parse Tokens with an associated coordinate.

    Turning tokens into a Tile objects which are then added to a maze
    """

    from .Maze import Maze
    _maze = Maze()

    def TokenParser(self,coordinate, token):
        """docstring for lass to parse Maze tokens and turn them into valid Tile obj"""
        # TODO: write code...
        pass

    def getMaze(self):
        """
        doc
        """
        return self._maze


